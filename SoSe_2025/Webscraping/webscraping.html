<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Advanced R for Econometricians</title>
    <meta charset="utf-8" />
    <meta name="author" content="Martin C. Arnold" />
    <meta name="author" content="Martin Schmelzer" />
    <meta name="date" content="2025-05-17" />
    <script src="webscraping_files/header-attrs/header-attrs.js"></script>
    <link href="webscraping_files/remark-css/default.css" rel="stylesheet" />
    <script src="webscraping_files/xaringanExtra-progressBar/progress-bar.js"></script>
    <script src="webscraping_files/clipboard/clipboard.min.js"></script>
    <link href="webscraping_files/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="webscraping_files/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"<i class=\"fa fa-clipboard\"><\/i>","success":"<i class=\"fa fa-check\" style=\"color: #00ff00\"><\/i>","error":"<i class=\"fa fa-times-circle\" style=\"color: #F94144\"><\/i>"})</script>
    <link href="webscraping_files/font-awesome/css/all.min.css" rel="stylesheet" />
    <link href="webscraping_files/font-awesome/css/v4-shims.min.css" rel="stylesheet" />
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        TeX: { equationNumbers: { autoNumber: "AMS" } },
      });
    </script>
    <style>
    .mjx-mrow a {
      color: black;
      pointer-events: none;
      cursor: default;
    }
    </style>
    <link rel="stylesheet" href="../assets/ude_fonts.css" type="text/css" />
    <link rel="stylesheet" href="../assets/ude.css" type="text/css" />
    <link rel="stylesheet" href="../assets/title_slides.css" type="text/css" />
    <link rel="stylesheet" href="../assets/custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: title-slide title-rvest center middle


<style>.xe__progress-bar__container {
  bottom:0;
  opacity: 1;
  position:absolute;
  right:0;
  left: 0;
}
.xe__progress-bar {
  height: 0.25em;
  background-color: #004c93;
  width: calc(var(--slide-current) / var(--slide-total) * 100%);
}
.remark-visible .xe__progress-bar {
  animation: xe__progress-bar__wipe 200ms forwards;
  animation-timing-function: cubic-bezier(.86,0,.07,1);
}
@keyframes xe__progress-bar__wipe {
  0% { width: calc(var(--slide-previous) / var(--slide-total) * 100%); }
  100% { width: calc(var(--slide-current) / var(--slide-total) * 100%); }
}</style>





# Advanced R for Econometricians
## Web Scraping with rvest
### Martin C. Arnold, Martin Schmelzer
---
class: left, top
## What is Web Scraping?

Web scraping is the process of extracting data from websites. It can be used if the desired data is not readily available via e.g. as a machine readable file to download or through an API.

--

.font90.blockquote.exercise[

#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

Consider the website https://www.trustpilot.com/ which is a platform for customer reviews.

]

--

Each review consists of different parts such as
- a short text
- a date
- a rating from 1 to 5 stars. 


--

Let's say we are interested whether the ratings of a shop change over time. For this we would need 
to gather the date and the star rating which are, however, not downloadable. 


We will learn how we can access this data nonetheless to perform the analysis. 

---
class: left, top
## Legal Issues

Webscraping is generally legal. However, depending on the jurisdiction it can be considered illegal in some cases.

--

You should be careful if...

- you have to sign in into e.g. a social network since you agree to their rules
- you circumvent web security measures
- you scrape personal information such as email addresses, etc. 
- you scrape a substantial amount of a website's content
- you want to republish the scraped content, e.g. an article from a newspage. 
- web scraping is prohibited by the Terms of Service, even if this doesn't make it illegal per se.  

--

**Important**: avoid troubles by limiting the number of requests to a reasonable amount (e.g. 1 request every 10 seconds). Otherwise it could be considered as a denial of service attack (DoS). 


---
## The Structure of a Website

.font80[
To extract data from a website it is necessary to understand the basics of how a website is built. 
]

--

.font70.blockquote.exercise[

#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Basic HTML example:

```{}
&lt;!DOCTYPE html&gt;
&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;Page Title&lt;/title&gt;
  &lt;/head&gt;
  &lt;body&gt;
    &lt;h1&gt;This is a Heading&lt;/h1&gt;
    &lt;p&gt;This is a paragraph.&lt;/p&gt;
  
    &lt;div&gt;
      &lt;h1&gt;This is another Heading&lt;/h1&gt;
      &lt;p&gt;This is another paragraph.&lt;/p&gt;
    &lt;/div&gt;
  &lt;/body&gt;
&lt;/html&gt;
```
]

--

.font80[
- The `&lt;html&gt;...&lt;/html&gt;` tags are the container for all other HTML elements.
- The `&lt;head&gt;...&lt;/head&gt;` tags contain meta data which are not directly visible on the web page.
- `&lt;body&gt;...&lt;/body&gt;` contains everything we can see such as text, links, images, tables, lists, etc. This is the most relevant part for web scraping. 
]
---
## The Body

.code70.blockquote.exercise[

#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example
```{}
&lt;body&gt;
  &lt;h1&gt;This is a Heading&lt;/h1&gt;
  &lt;p&gt;This is a paragraph.&lt;/p&gt;
  
  &lt;div&gt;
    &lt;h1&gt;This is another Heading&lt;/h1&gt;
    &lt;p&gt;This is another paragraph.&lt;/p&gt;
  &lt;/div&gt;
&lt;/body&gt;
```
]

--

.font90[
- In the body part tags are used to give the displayed information a structure. In our example we use: 
    - `&lt;h1&gt;...&lt;/h1&gt;`   to define a heading
    - `&lt;p&gt;...&lt;/p&gt;`     to define a paragraph
    - `&lt;div&gt;...&lt;/div&gt;` to define different sections.

- Look at the [w3schools tag list](https://www.w3schools.com/tags/default.asp) for other tags you might encounter. 
]

--

.font90[
We will start by scraping the simple HTML page from before. 
Create a new HTML document and copy the code from the previous slide into it.
]

---
## `read_html()`


The `rvest` package leverages the structure of an HTML document to extract relevant information.

The first step is to load the website into R using `read_html()`.

&lt;br&gt;

--

.font90.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example


``` r
library(rvest)
page_url &lt;- here::here("SoSe_2025/Webscraping/examples/simple_html_page.html")
(doc &lt;- rvest::read_html(page_url))
```

```
## {html_document}
## &lt;html&gt;
## [1] &lt;head&gt;\n&lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8 ...
## [2] &lt;body&gt;\n  &lt;h1&gt;This is a Heading&lt;/h1&gt;\n  &lt;p&gt;This is a paragraph.&lt;/p&gt;\n  &lt;d ...
```
]

---
## XML Structure

.font90[
Our page is now stored as an `xml` document which has a hierarchical data structure. For our page it looks like this. ]

&lt;img src="xml_structure1.png" width="600px" style="display: block; margin: auto;" /&gt;

--

.font90[
- We call everything surrounded by a rectangle or a circle a node. 
- We call everything surrounded by a rectangle with rounded corners data. 
]
---
## `html_element()`

We can navigate through the `xml` object using `rvest::html_element()` and `rvest::html_elements()`.

- Get all `p` nodes

.font80.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example


``` r
doc %&gt;% html_elements("p")
```

```
## {xml_nodeset (2)}
## [1] &lt;p&gt;This is a paragraph.&lt;/p&gt;
## [2] &lt;p&gt;This is another paragraph.&lt;/p&gt;
```
]


--

- Get only `p` nodes which are children of `div` nodes

.font80.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example


``` r
doc %&gt;% 
  html_elements("div") %&gt;% 
  html_elements("p")
```

```
## {xml_nodeset (1)}
## [1] &lt;p&gt;This is another paragraph.&lt;/p&gt;
```
]



---
## `html_text()`
If we got the nodes which contain the data we want to scrape, we can use `rvest::html_text()` to 
extract the data (i.e. the text between the tags) as a normal character vector. 

&lt;br&gt;

--


.font90.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

``` r
doc %&gt;% 
  html_elements("div") %&gt;% 
  html_elements("p") %&gt;%  
  html_text()
```

```
## [1] "This is another paragraph."
```
]





---
## CSS 

.font90[
Websites are not only built with HTML. CSS is the language which is used to style a website.
Let's add a bit more to our simple page: 

- add a link to a `css` file (which doesn't exist now) in the head section of your html file 
.blockquote.exercise[
```{}
&lt;link rel="stylesheet" href="stylesheet.css"&gt;
```
]]

--

.font90[
- add another `div` with a heading and a paragraph

- create a new file `stylesheet.css` in the same folder as your HTML file 

- copy the following code into that file and see what happens]

--

.blockquote.exercise[
```{}
div h1 {
  color: green;
  text-align: center;
};
```
]

---
## CSS Selectors

What if we want different `div` sections to look differently?

For this classes and ids can be specified. For web scraping we usually only need 
to know about classes, but ids work quite similar. 

--

- change the code of one `div` section to  
.blockquote.exercise[
```{}
&lt;div class = "blue"&gt; ... &lt;/div&gt; 
```
]
- and the other to 
.blockquote.exercise[
```{}
&lt;div class = "red"&gt; ... &lt;/div&gt; 
```
]
---
## CSS Selectors

.font80[
Having added a class attribute to our `div` sections, we can now use this class in the CSS file as follows
]
--

.pull-left-1.font80.blockquote.exercise[
```{}
.blue h1 {
  color: blue;
  text-align: center;
}

.red h1 {
  color: green;
  text-align: center;
}
```
]

.pull-right-2[
- What is before the `{}` is called a CSS selector. 
  - It can consist of classes, ids, tags and of any combination of those elements. 
  - E.g. `.blue h1` reads as: select all `h1` headings inside an element with class `blue`.
  - Note: you need to put a `.` before the class name. 
]

--

.pull-down[ &lt;br&gt;&lt;br&gt;
For more on selectors look at [w3chools CSS Selector Reference](https://www.w3schools.com/cssref/css_selectors.asp).
&lt;br&gt;
&lt;br&gt;
&lt;br&gt;
`\(\qquad\)`
]

--

.pull-down[
The web developer uses selectors to style similar content in the same way (e.g. on trustpilot.com 
each user review looks the same). We can use those to scrape the content we desire more specifically.   
]

---
## Use the Selectors 

Let's say we want to select all paragraphs (`p`) which are a descendant of an element with class `.red`. We can achieve this with

--

.font90.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

``` r
page_url &lt;- here::here("SoSe_2025/Webscraping/examples/simple_html_page_with_css.html")
doc &lt;- read_html(page_url)
doc %&gt;%  
  html_elements(".red") %&gt;% 
  html_elements("p") %&gt;%
  html_text()
```

```
## [1] "But this isn't red."
```
]

--

or in short
.font90.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example


``` r
doc %&gt;%  
  html_elements(".red p") %&gt;% 
  html_text()
```
]

---
## Extract attributes

.font70[
Sometimes we are not interested in the text between element tags but the relevant information is hidden in the tag attributes. 

Attributes are everything that is defined in the opening tag, e.g in 
]

--

.font70.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

```{}
&lt;div class = "blue"&gt; ... &lt;/div&gt; 
```
]

--

.font70[
- `class = "blue"` is an attribute. 

With `html_attrs()` and `html_attr()`  we can extract these information.
]

--

.font70.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

``` r
# Get all attributes
doc %&gt;%  
  html_elements(".red") %&gt;% 
  html_attrs()

# Get a specific attribute
doc %&gt;%  
  html_elements(".red") %&gt;% 
  html_attr("class")
```
]

---
## HTML tables 

.font80[
Since data is often stored in tables, `rvest` provides the function `html_table()` which parses an HTML table into a data frame. Tables in HTML look like this: 
]
--
.pull-left-1[
.font80.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

```{}
&lt;table style="width:100%"&gt;
  &lt;tr&gt;
    &lt;th&gt;Firstname&lt;/th&gt;
    &lt;th&gt;Lastname&lt;/th&gt;
    &lt;th&gt;Age&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Jill&lt;/td&gt;
    &lt;td&gt;Smith&lt;/td&gt;
    &lt;td&gt;50&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Eve&lt;/td&gt;
    &lt;td&gt;Jackson&lt;/td&gt;
    &lt;td&gt;94&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
```
]]


--
.pull-right-2.font80[
&lt;br&gt; &lt;br&gt;
.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Exercise:
- Add this table to your HTML file.
- Try to scrape the data using `html_table()`
]

]
---
## CSS Selector Gadget

How do we find the CSS selectors

1. Looking into the source code (depending on your web browser you can right click on
   the webpage and click e.g. source code, inspect, ...)

2. Digging through the source code is often not necessary. If you use Chrome install 
   the [Selector Gadget](https://rvest.tidyverse.org/articles/selectorgadget.html).



---
## Dynamically injected content

Modern webpages often dynamically inject content. Take
[ESPN NBA Player statistics](https://www.espn.com/nba/stats/player) as an example.

In such cases you can make use of a "headless" (no graphical user interface) browser. `rvest::read_html_live` uses the `chromote` package which is an R implementation of the Chrome DevTools Protocol.

Instead of reading the DOM (the source code) into R, a headless instance of a Chromium based browser (usually Chrome) opens the URL in the background.


.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

``` r
# Static
doc &lt;- read_html("https://www.espn.com/nba/stats/player")

# Dynamic
sess &lt;- read_html_live("https://www.espn.com/nba/stats/player")
```
]

---
## Dynamically injected content
.blockquote.exercise[
#### &lt;svg viewBox="0 0 576 512" style="height:1em;position:relative;display:inline-block;top:.1em;fill:#004c93;" xmlns="http://www.w3.org/2000/svg"&gt;  &lt;path d="M528 0H48C21.5 0 0 21.5 0 48v320c0 26.5 21.5 48 48 48h192l-16 48h-72c-13.3 0-24 10.7-24 24s10.7 24 24 24h272c13.3 0 24-10.7 24-24s-10.7-24-24-24h-72l-16-48h192c26.5 0 48-21.5 48-48V48c0-26.5-21.5-48-48-48zm-16 352H64V64h448v288z"&gt;&lt;/path&gt;&lt;/svg&gt; Example

``` r
players_xpath &lt;- "/html/body/div[1]/div/div/div/div/main/div[2]/div[2]/div/div/section/div/div[3]/div[1]/div/table"
# Static
doc %&gt;%
  html_elements(players_xpath) %&gt;%
  html_table()

# Dynamic
sess %&gt;%
  html_elements(players_xpath) %&gt;%
  html_table()

# Load more rows
sess$click(".loadMore__link")
sess %&gt;%
  html_elements(players_xpath) %&gt;%
  html_table()
```
]


---
class: exercise_slide
## Exercise


Checkout https://books.toscrape.com/ which is a great and safe sandbox to learn
about webscraping.

1. Scrape all book titles from the landing page.

2. Additionally, scrape prices and star ratings, format the data appropriately and
combine the data in a tibble.

3. Scrape multiple pages (add pagination). We know that there are 50 pages, but can
you make the scraper flexible in case there are more pages in the future?
*Hint:* use `httr::GET` and `httr::status_code`.









    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="../assets/navigate_home.js"></script>
<script src="../assets/remark-zoom.js"></script>
<script src="../xaringan_files/macros.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
  "highlightStyle": "github",
  "highlightLines": true,
  "countIncrementalSlides": false,
  "ratio": "16:9",
  "navigation": {
    "scroll": false
  }
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
